{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23578581-442f-4827-8e78-03948d7a711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4f826-2025-43b5-b278-edf8538a3475",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6972e64-4f68-4f4a-a0d3-992b675c0cc1",
   "metadata": {},
   "source": [
    "## Load all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8089967e-6d0e-464d-83b1-1e14c8a4b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', 'Alzheimer_s Dataset')\n",
    "synth_dir = os.path.join('data','synth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad92622e-97b9-4544-be49-22e62ad5ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0e751346-fd2a-4665-a0eb-bc40897e7562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3],\n",
       " [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "real_train_class_idx = {v: k for k,v in real_train_dataset.class_to_idx.items()}\n",
    "real_train_target = [real_train_class_idx[t] for t in real_train_dataset.targets]\n",
    "\n",
    "plt.hist(real_train_target)\n",
    "plt.title('Class distribution')\n",
    "plt.ylabel('# samples')\n",
    "plt.xlabel('class')\n",
    "plt.xticks(rotation = 45) # Rotates X-Axis Ticks by 45-degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b695234-640d-4c81-9f52-1d6f547a5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'),\n",
    "                                          data_transforms['train'])\n",
    "\n",
    "synth_dataset_train = datasets.ImageFolder(os.path.join(synth_dir, 'train'),\n",
    "                                     data_transforms['train'])\n",
    "\n",
    "synth_dataset_test = datasets.ImageFolder(os.path.join(synth_dir, 'test'),\n",
    "                                     data_transforms['test'])\n",
    "\n",
    "real_synth_train = ConcatDataset([real_train_dataset, synth_dataset_train])\n",
    "\n",
    "real_test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'),\n",
    "                                          data_transforms['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f307b-b33e-429c-9faa-da11c487a7c4",
   "metadata": {},
   "source": [
    "## Prepare and select datasets for training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6cd1107-62df-4de2-83ce-3708849e7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_sets = {\n",
    "    'real': real_train_dataset,\n",
    "    'real_synth': real_synth_train,\n",
    "    'synth': synth_dataset_train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f624bda9-a326-4d5e-9c9f-0d5b81f27d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET_NAME = 'real_synth'\n",
    "image_datasets = {\n",
    "    'train': all_training_sets[TRAIN_SET_NAME],\n",
    "    'test': real_test_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a926aee-4ec9-4b73-baee-a26a45a01e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=128,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=4)\n",
    "               for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['test'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f46ba-c942-4ca8-b4b9-86786cb059bf",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579940e8-d1ae-4634-8f92-d4ca27e34aeb",
   "metadata": {},
   "source": [
    "## Code for viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "210744f9-616b-447f-b190-1606c79bbf0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mpause(\u001b[38;5;241m0.001\u001b[39m)  \u001b[38;5;66;03m# pause a bit so that plots are updated\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Get a batch of training data\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m inputs, classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mdataloaders\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Make a grid from batch\u001b[39;00m\n\u001b[1;32m     18\u001b[0m out \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mmake_grid(inputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"
     ]
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a1e923-17be-4ef7-bb01-631803866733",
   "metadata": {},
   "source": [
    "## Code for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a75154d-3c10-4f4c-9ffc-9985939b2264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, dataloader, device, criterion = nn.CrossEntropyLoss()):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "        \n",
    "    return float(epoch_loss), float(epoch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b863b6-6176-49fd-80f3-246254bf3d99",
   "metadata": {},
   "source": [
    "## code for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa0ae10a-b7f9-44c9-9868-0eea4b323ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    metrics_loss = []\n",
    "    metrics_acc = []\n",
    "    metrics = {'train': {'loss': [], 'accuracy': []},\n",
    "               'test':  {'loss': [], 'accuracy': []},\n",
    "              }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            metrics[phase]['loss'].append(float(epoch_loss))\n",
    "            metrics[phase]['accuracy'].append(float(epoch_acc))\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, {'loss': metrics_loss, 'accuracy': metrics_acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1527c97-0eed-47d3-b3a3-9e7f347d68a5",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a14e6b-a7be-4951-9bf7-689a4612e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "model_ft = resnet50(weights=weights)\n",
    "num_ftrs = model_ft.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a9a7f018-7903-41bb-beca-2a7b985e71f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StepLR in module torch.optim.lr_scheduler:\n",
      "\n",
      "class StepLR(_LRScheduler)\n",
      " |  StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1, verbose=False)\n",
      " |  \n",
      " |  Decays the learning rate of each parameter group by gamma every\n",
      " |  step_size epochs. Notice that such decay can happen simultaneously with\n",
      " |  other changes to the learning rate from outside this scheduler. When\n",
      " |  last_epoch=-1, sets initial lr as lr.\n",
      " |  \n",
      " |  Args:\n",
      " |      optimizer (Optimizer): Wrapped optimizer.\n",
      " |      step_size (int): Period of learning rate decay.\n",
      " |      gamma (float): Multiplicative factor of learning rate decay.\n",
      " |          Default: 0.1.\n",
      " |      last_epoch (int): The index of last epoch. Default: -1.\n",
      " |      verbose (bool): If ``True``, prints a message to stdout for\n",
      " |          each update. Default: ``False``.\n",
      " |  \n",
      " |  Example:\n",
      " |      >>> # Assuming optimizer uses lr = 0.05 for all groups\n",
      " |      >>> # lr = 0.05     if epoch < 30\n",
      " |      >>> # lr = 0.005    if 30 <= epoch < 60\n",
      " |      >>> # lr = 0.0005   if 60 <= epoch < 90\n",
      " |      >>> # ...\n",
      " |      >>> scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
      " |      >>> for epoch in range(100):\n",
      " |      >>>     train(...)\n",
      " |      >>>     validate(...)\n",
      " |      >>>     scheduler.step()\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StepLR\n",
      " |      _LRScheduler\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, optimizer, step_size, gamma=0.1, last_epoch=-1, verbose=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_lr(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _LRScheduler:\n",
      " |  \n",
      " |  get_last_lr(self)\n",
      " |      Return last computed learning rate by current scheduler.\n",
      " |  \n",
      " |  load_state_dict(self, state_dict)\n",
      " |      Loads the schedulers state.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): scheduler state. Should be an object returned\n",
      " |              from a call to :meth:`state_dict`.\n",
      " |  \n",
      " |  print_lr(self, is_verbose, group, lr, epoch=None)\n",
      " |      Display the current learning rate.\n",
      " |  \n",
      " |  state_dict(self)\n",
      " |      Returns the state of the scheduler as a :class:`dict`.\n",
      " |      \n",
      " |      It contains an entry for every variable in self.__dict__ which\n",
      " |      is not the optimizer.\n",
      " |  \n",
      " |  step(self, epoch=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _LRScheduler:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lr_scheduler.StepLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f609dd27-de9b-4b18-9ff4-413cd69ef15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cbfee72-c01e-4fca-b8db-e13fb2c294d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.9222 Acc: 0.6564\n",
      "test Loss: 1.0335 Acc: 0.5016\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.3487 Acc: 0.8591\n",
      "test Loss: 1.0275 Acc: 0.5008\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.2670 Acc: 0.8821\n",
      "test Loss: 0.9449 Acc: 0.5094\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.2433 Acc: 0.8881\n",
      "test Loss: 0.9221 Acc: 0.5195\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.2260 Acc: 0.8973\n",
      "test Loss: 0.9555 Acc: 0.5227\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.2200 Acc: 0.8990\n",
      "test Loss: 0.8928 Acc: 0.5539\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.2098 Acc: 0.9039\n",
      "test Loss: 0.9500 Acc: 0.5367\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.2046 Acc: 0.9041\n",
      "test Loss: 0.8942 Acc: 0.5648\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.2021 Acc: 0.9058\n",
      "test Loss: 0.9046 Acc: 0.5516\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.2049 Acc: 0.9044\n",
      "test Loss: 0.8918 Acc: 0.5586\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.2023 Acc: 0.9062\n",
      "test Loss: 0.8872 Acc: 0.5602\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.2014 Acc: 0.9061\n",
      "test Loss: 0.8954 Acc: 0.5602\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.2012 Acc: 0.9085\n",
      "test Loss: 0.8911 Acc: 0.5664\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.1994 Acc: 0.9071\n",
      "test Loss: 0.8820 Acc: 0.5680\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.2010 Acc: 0.9079\n",
      "test Loss: 0.8808 Acc: 0.5680\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.2002 Acc: 0.9089\n",
      "test Loss: 0.8737 Acc: 0.5750\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.1971 Acc: 0.9100\n",
      "test Loss: 0.8862 Acc: 0.5664\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.1981 Acc: 0.9082\n",
      "test Loss: 0.8797 Acc: 0.5742\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.1994 Acc: 0.9100\n",
      "test Loss: 0.8820 Acc: 0.5695\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.1979 Acc: 0.9092\n",
      "test Loss: 0.8837 Acc: 0.5703\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.1995 Acc: 0.9086\n",
      "test Loss: 0.8798 Acc: 0.5703\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.1980 Acc: 0.9085\n",
      "test Loss: 0.8832 Acc: 0.5727\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.1990 Acc: 0.9100\n",
      "test Loss: 0.8850 Acc: 0.5727\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.1990 Acc: 0.9079\n",
      "test Loss: 0.8888 Acc: 0.5633\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.1983 Acc: 0.9092\n",
      "test Loss: 0.8882 Acc: 0.5664\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.2002 Acc: 0.9097\n",
      "test Loss: 0.8828 Acc: 0.5695\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.1977 Acc: 0.9084\n",
      "test Loss: 0.8831 Acc: 0.5781\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.2010 Acc: 0.9074\n",
      "test Loss: 0.8743 Acc: 0.5727\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.1991 Acc: 0.9088\n",
      "test Loss: 0.8902 Acc: 0.5648\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.1978 Acc: 0.9098\n",
      "test Loss: 0.8810 Acc: 0.5695\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.1985 Acc: 0.9092\n",
      "test Loss: 0.8805 Acc: 0.5719\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.1989 Acc: 0.9089\n",
      "test Loss: 0.8729 Acc: 0.5781\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.1971 Acc: 0.9081\n",
      "test Loss: 0.8823 Acc: 0.5727\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.1998 Acc: 0.9084\n",
      "test Loss: 0.8892 Acc: 0.5672\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.1976 Acc: 0.9086\n",
      "test Loss: 0.8748 Acc: 0.5766\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.2007 Acc: 0.9072\n",
      "test Loss: 0.8871 Acc: 0.5656\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.2012 Acc: 0.9069\n",
      "test Loss: 0.8839 Acc: 0.5734\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.1971 Acc: 0.9099\n",
      "test Loss: 0.8801 Acc: 0.5687\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.1982 Acc: 0.9067\n",
      "test Loss: 0.8830 Acc: 0.5680\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.2006 Acc: 0.9081\n",
      "test Loss: 0.8777 Acc: 0.5813\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.1979 Acc: 0.9085\n",
      "test Loss: 0.8894 Acc: 0.5625\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.2007 Acc: 0.9071\n",
      "test Loss: 0.8771 Acc: 0.5750\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.2002 Acc: 0.9080\n",
      "test Loss: 0.8803 Acc: 0.5789\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.2012 Acc: 0.9060\n",
      "test Loss: 0.8902 Acc: 0.5656\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.1975 Acc: 0.9104\n",
      "test Loss: 0.8859 Acc: 0.5672\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.1997 Acc: 0.9094\n",
      "test Loss: 0.8849 Acc: 0.5695\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.1971 Acc: 0.9099\n",
      "test Loss: 0.8832 Acc: 0.5750\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.1995 Acc: 0.9089\n",
      "test Loss: 0.8785 Acc: 0.5719\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.1992 Acc: 0.9069\n",
      "test Loss: 0.8751 Acc: 0.5820\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.2022 Acc: 0.9069\n",
      "test Loss: 0.8881 Acc: 0.5633\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.1989 Acc: 0.9085\n",
      "test Loss: 0.8748 Acc: 0.5797\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.2001 Acc: 0.9069\n",
      "test Loss: 0.8892 Acc: 0.5695\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.1993 Acc: 0.9073\n",
      "test Loss: 0.8796 Acc: 0.5695\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.2000 Acc: 0.9069\n",
      "test Loss: 0.8791 Acc: 0.5727\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.1971 Acc: 0.9086\n",
      "test Loss: 0.8820 Acc: 0.5695\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.1982 Acc: 0.9084\n",
      "test Loss: 0.8861 Acc: 0.5602\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.1995 Acc: 0.9067\n",
      "test Loss: 0.8862 Acc: 0.5664\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.2017 Acc: 0.9073\n",
      "test Loss: 0.8809 Acc: 0.5672\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.2007 Acc: 0.9076\n",
      "test Loss: 0.8867 Acc: 0.5625\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.2003 Acc: 0.9072\n",
      "test Loss: 0.8785 Acc: 0.5766\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.2023 Acc: 0.9061\n",
      "test Loss: 0.8822 Acc: 0.5648\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.1994 Acc: 0.9073\n",
      "test Loss: 0.8840 Acc: 0.5797\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.2010 Acc: 0.9062\n",
      "test Loss: 0.8783 Acc: 0.5687\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.1975 Acc: 0.9090\n",
      "test Loss: 0.8905 Acc: 0.5625\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.1985 Acc: 0.9091\n",
      "test Loss: 0.8795 Acc: 0.5727\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.1973 Acc: 0.9097\n",
      "test Loss: 0.8922 Acc: 0.5648\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.1993 Acc: 0.9080\n",
      "test Loss: 0.8816 Acc: 0.5727\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.1995 Acc: 0.9077\n",
      "test Loss: 0.8934 Acc: 0.5703\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.1985 Acc: 0.9086\n",
      "test Loss: 0.8804 Acc: 0.5750\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.2015 Acc: 0.9068\n",
      "test Loss: 0.8796 Acc: 0.5727\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.2011 Acc: 0.9080\n",
      "test Loss: 0.8733 Acc: 0.5797\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.1989 Acc: 0.9095\n",
      "test Loss: 0.8802 Acc: 0.5695\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.1984 Acc: 0.9067\n",
      "test Loss: 0.8829 Acc: 0.5758\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.1985 Acc: 0.9086\n",
      "test Loss: 0.8771 Acc: 0.5758\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.1986 Acc: 0.9076\n",
      "test Loss: 0.8778 Acc: 0.5680\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.1973 Acc: 0.9080\n",
      "test Loss: 0.8805 Acc: 0.5742\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.1974 Acc: 0.9090\n",
      "test Loss: 0.8850 Acc: 0.5680\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.1981 Acc: 0.9088\n",
      "test Loss: 0.8797 Acc: 0.5719\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.1977 Acc: 0.9092\n",
      "test Loss: 0.8882 Acc: 0.5687\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.1990 Acc: 0.9075\n",
      "test Loss: 0.8773 Acc: 0.5727\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.2016 Acc: 0.9068\n",
      "test Loss: 0.8836 Acc: 0.5734\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.1979 Acc: 0.9091\n",
      "test Loss: 0.8815 Acc: 0.5664\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.2007 Acc: 0.9072\n",
      "test Loss: 0.8755 Acc: 0.5773\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.1987 Acc: 0.9080\n",
      "test Loss: 0.8766 Acc: 0.5750\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.1983 Acc: 0.9087\n",
      "test Loss: 0.8798 Acc: 0.5727\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.1991 Acc: 0.9064\n",
      "test Loss: 0.8777 Acc: 0.5789\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.1986 Acc: 0.9083\n",
      "test Loss: 0.8798 Acc: 0.5734\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.1979 Acc: 0.9082\n",
      "test Loss: 0.8891 Acc: 0.5727\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.1994 Acc: 0.9067\n",
      "test Loss: 0.8767 Acc: 0.5734\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.1979 Acc: 0.9085\n",
      "test Loss: 0.8780 Acc: 0.5727\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.1999 Acc: 0.9097\n",
      "test Loss: 0.8792 Acc: 0.5664\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.1975 Acc: 0.9096\n",
      "test Loss: 0.8896 Acc: 0.5672\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.1991 Acc: 0.9082\n",
      "test Loss: 0.8772 Acc: 0.5719\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.1982 Acc: 0.9085\n",
      "test Loss: 0.8790 Acc: 0.5750\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.1996 Acc: 0.9068\n",
      "test Loss: 0.8740 Acc: 0.5750\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.1970 Acc: 0.9086\n",
      "test Loss: 0.8857 Acc: 0.5758\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.2014 Acc: 0.9072\n",
      "test Loss: 0.8765 Acc: 0.5797\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "train Loss: 0.1998 Acc: 0.9091\n",
      "test Loss: 0.8759 Acc: 0.5750\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.1986 Acc: 0.9073\n",
      "test Loss: 0.8790 Acc: 0.5742\n",
      "\n",
      "Training complete in 206m 32s\n",
      "Best val Acc: 0.582031\n"
     ]
    }
   ],
   "source": [
    "model_ft, metrics = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ab178-71cb-4802-82f6-8950809f6bf2",
   "metadata": {},
   "source": [
    "## Store model and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef8dd0a0-c9c3-45c3-b603-df90d3162974",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_datetime_prefix = datetime.datetime.now().strftime(f'%Y_%m_%d_%H_%M')\n",
    "torch.save(model_ft, f'{fn_datetime_prefix}__{TRAIN_SET_NAME}_model.pt')\n",
    "with open(f'{fn_datetime_prefix}__{TRAIN_SET_NAME}_metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210096c-e108-4102-ac56-dd3e38ca9ff1",
   "metadata": {},
   "source": [
    "## Results compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e34fab6-1c53-4de3-9b1b-13e5e215fde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train dataset</th>\n",
       "      <th>best train acc</th>\n",
       "      <th>best_test_acc</th>\n",
       "      <th>epochs</th>\n",
       "      <th>test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>0.548438</td>\n",
       "      <td>100</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>0.139800</td>\n",
       "      <td>100</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>0.909600</td>\n",
       "      <td>100</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>real+synth</td>\n",
       "      <td>0.9069</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>100</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train dataset  best train acc  best_test_acc  epochs   test set\n",
       "0          real          0.5695       0.548438     100       real\n",
       "1     synthetic          0.9874       0.139800     100       real\n",
       "2     synthetic          0.9874       0.909600     100  synthetic\n",
       "3    real+synth          0.9069       0.582000     100       real"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'train dataset': ['real','synthetic', 'synthetic', 'real+synth'],                   \n",
    "                   'best train acc': [0.5695, 0.9874, 0.9874, 0.9069],\n",
    "                   'best_test_acc': [0.548438, 0.1398, 0.9096, 0.5820],\n",
    "                   'epochs': [100, 100, 100, 100],\n",
    "                   'test set': ['real', 'real', 'synthetic', 'real']\n",
    "                  }\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d4c2b-45fa-4c01-814d-8121cbd4e5b7",
   "metadata": {},
   "source": [
    "# Inference from loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3f1042d-8c5e-408f-8ad9-bab849376102",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = !ls *.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34632a4-1638-4c30-9b8c-641b88599fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2022_07_23_01_27__real_model.pt\n",
      "1 2022_07_23_07_58__synth_model.pt\n",
      "2 2022_07_23_11_33__real_synth_model.pt\n",
      "3 MildDemented_discriminator.pt\n",
      "4 MildDemented_generator.pt\n",
      "5 ModerateDemented_discriminator.pt\n",
      "6 ModerateDemented_generator.pt\n",
      "7 NonDemented_discriminator.pt\n",
      "8 NonDemented_generator.pt\n",
      "9 VeryMildDemented_discriminator.pt\n",
      "10 VeryMildDemented_generator.pt\n"
     ]
    }
   ],
   "source": [
    "for i,fn in enumerate(models):\n",
    "    print(i, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d45f903c-bc3e-476e-8f31-39472ea0af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_fn = [\n",
    "    '2022_07_23_01_27__real_model.pt',\n",
    "    '2022_07_23_07_58__synth_model.pt',\n",
    "    '2022_07_23_11_33__real_synth_model.pt'\n",
    "]\n",
    "\n",
    "datasets = {\n",
    "    'real train': real_train_dataset,\n",
    "    'synth train': synth_dataset_train,\n",
    "    'synth test': synth_dataset_test,\n",
    "    'real synth train': real_synth_train,\n",
    "    'real test': real_test_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e66b1fc-fd5f-4a9c-bc6a-82ae043950bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = models[2]\n",
    "chosen_dataset = synth_dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d9bea-cd1f-427d-bd54-7633f61e8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c406b190-d003-4d47-b82a-940ce85783d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model_fn: str, dataset):\n",
    "    model = torch.load(model_fn)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                             batch_size=128,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=4)\n",
    "\n",
    "    class_names = real_train_dataset.classes\n",
    "    \n",
    "    return inference(model, dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12aaedc8-78f9-46ff-8a47-e49d2f1b52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_fn)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(chosen_dataset,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=4)\n",
    "\n",
    "class_names = real_train_dataset.classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "270e6639-20d0-488a-931d-25a11d80b1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2022_07_23_01_27__real_model.pt real train 0.5663803201874268\n",
      "1 2022_07_23_01_27__real_model.pt synth train 0.252\n",
      "2 2022_07_23_01_27__real_model.pt synth test 0.2595\n",
      "3 2022_07_23_01_27__real_model.pt real synth train 0.3184061778520818\n",
      "4 2022_07_23_01_27__real_model.pt real test 0.5375\n",
      "5 2022_07_23_07_58__synth_model.pt real train 0.138227254978524\n",
      "6 2022_07_23_07_58__synth_model.pt synth train 0.97465\n",
      "7 2022_07_23_07_58__synth_model.pt synth test 0.9965\n",
      "8 2022_07_23_07_58__synth_model.pt real synth train 0.8049916407929304\n",
      "9 2022_07_23_07_58__synth_model.pt real test 0.13984375000000002\n",
      "10 2022_07_23_11_33__real_synth_model.pt real train 0.5999609527528309\n",
      "11 2022_07_23_11_33__real_synth_model.pt synth train 0.9900500000000001\n",
      "12 2022_07_23_11_33__real_synth_model.pt synth test 1.0\n",
      "13 2022_07_23_11_33__real_synth_model.pt real synth train 0.9125467717538411\n",
      "14 2022_07_23_11_33__real_synth_model.pt real test 0.58203125\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(itertools.product(models_fn, datasets.keys()), columns=['model', 'dataset'])\n",
    "results['accuracy'] = -1\n",
    "results['loss'] = -1\n",
    "\n",
    "for i, model_dataset in enumerate(itertools.product(models_fn, datasets.keys())):\n",
    "    model_fn, dataset_name = model_dataset\n",
    "    loss, acc = run_inference(model_fn, datasets[dataset_name])\n",
    "    results.at[i, 'loss'] = loss\n",
    "    results.at[i, 'accuracy'] = acc\n",
    "    print(i, model_fn, dataset_name, acc)\n",
    "    #print(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "01f7fcac-21a1-4ca3-b607-71b961829a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022_07_23_01_27__real_model.pt</td>\n",
       "      <td>real train</td>\n",
       "      <td>0.566380</td>\n",
       "      <td>0.882146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022_07_23_01_27__real_model.pt</td>\n",
       "      <td>synth train</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>1.721778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022_07_23_01_27__real_model.pt</td>\n",
       "      <td>synth test</td>\n",
       "      <td>0.259500</td>\n",
       "      <td>1.695184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022_07_23_01_27__real_model.pt</td>\n",
       "      <td>real synth train</td>\n",
       "      <td>0.318406</td>\n",
       "      <td>1.550967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022_07_23_01_27__real_model.pt</td>\n",
       "      <td>real test</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.914505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022_07_23_07_58__synth_model.pt</td>\n",
       "      <td>real train</td>\n",
       "      <td>0.138227</td>\n",
       "      <td>7.253116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022_07_23_07_58__synth_model.pt</td>\n",
       "      <td>synth train</td>\n",
       "      <td>0.974650</td>\n",
       "      <td>0.078957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022_07_23_07_58__synth_model.pt</td>\n",
       "      <td>synth test</td>\n",
       "      <td>0.996500</td>\n",
       "      <td>0.022740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022_07_23_07_58__synth_model.pt</td>\n",
       "      <td>real synth train</td>\n",
       "      <td>0.804992</td>\n",
       "      <td>1.539548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022_07_23_07_58__synth_model.pt</td>\n",
       "      <td>real test</td>\n",
       "      <td>0.139844</td>\n",
       "      <td>7.768363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022_07_23_11_33__real_synth_model.pt</td>\n",
       "      <td>real train</td>\n",
       "      <td>0.599961</td>\n",
       "      <td>0.816702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022_07_23_11_33__real_synth_model.pt</td>\n",
       "      <td>synth train</td>\n",
       "      <td>0.990050</td>\n",
       "      <td>0.029399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022_07_23_11_33__real_synth_model.pt</td>\n",
       "      <td>synth test</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022_07_23_11_33__real_synth_model.pt</td>\n",
       "      <td>real synth train</td>\n",
       "      <td>0.912547</td>\n",
       "      <td>0.188729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022_07_23_11_33__real_synth_model.pt</td>\n",
       "      <td>real test</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.875055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model           dataset  accuracy  \\\n",
       "0         2022_07_23_01_27__real_model.pt        real train  0.566380   \n",
       "1         2022_07_23_01_27__real_model.pt       synth train  0.252000   \n",
       "2         2022_07_23_01_27__real_model.pt        synth test  0.259500   \n",
       "3         2022_07_23_01_27__real_model.pt  real synth train  0.318406   \n",
       "4         2022_07_23_01_27__real_model.pt         real test  0.537500   \n",
       "5        2022_07_23_07_58__synth_model.pt        real train  0.138227   \n",
       "6        2022_07_23_07_58__synth_model.pt       synth train  0.974650   \n",
       "7        2022_07_23_07_58__synth_model.pt        synth test  0.996500   \n",
       "8        2022_07_23_07_58__synth_model.pt  real synth train  0.804992   \n",
       "9        2022_07_23_07_58__synth_model.pt         real test  0.139844   \n",
       "10  2022_07_23_11_33__real_synth_model.pt        real train  0.599961   \n",
       "11  2022_07_23_11_33__real_synth_model.pt       synth train  0.990050   \n",
       "12  2022_07_23_11_33__real_synth_model.pt        synth test  1.000000   \n",
       "13  2022_07_23_11_33__real_synth_model.pt  real synth train  0.912547   \n",
       "14  2022_07_23_11_33__real_synth_model.pt         real test  0.582031   \n",
       "\n",
       "        loss  \n",
       "0   0.882146  \n",
       "1   1.721778  \n",
       "2   1.695184  \n",
       "3   1.550967  \n",
       "4   0.914505  \n",
       "5   7.253116  \n",
       "6   0.078957  \n",
       "7   0.022740  \n",
       "8   1.539548  \n",
       "9   7.768363  \n",
       "10  0.816702  \n",
       "11  0.029399  \n",
       "12  0.002105  \n",
       "13  0.188729  \n",
       "14  0.875055  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8fc7cc91-3afa-4f54-86ef-27a9c92a57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel('models_results.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f21b216-ea0a-40df-9072-e6f148abd41f",
   "metadata": {},
   "source": [
    "# ------ END ------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
